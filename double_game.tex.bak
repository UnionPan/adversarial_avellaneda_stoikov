%% 
%% Copyright 2007-2024 Elsevier Ltd
%% 
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.3 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.3 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%% 
%% Template article for Elsevier's document class `elsarticle'
%% with numbered style bibliographic references
%% SP 2008/03/01
%% $Id: elsarticle-template-num.tex 249 2024-04-06 10:51:24Z rishi $
%%
\documentclass[preprint,12pt]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[authoryear,preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}

\usepackage{graphicx}
\usepackage{amsmath,amssymb,mathtools}
\usepackage{booktabs}
\let\theoremstyle\relax % avoid clash between ifacconf.cls (theorem) and amsthm
\usepackage{amsthm}
\let\AND\relax % avoid clash between ifacconf author macro and algorithmic package
\usepackage{algorithm,algorithmic}
\usepackage{natbib}
\usepackage{glossaries}

\newtheorem{assumption}{Assumption}
\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}
\newacronym{ctmc}{CTMC}{Continuous Time Markov Chain}
\newacronym{hji}{HJI}{Hamilton-Jacobian-Issacs}
\newacronym{pdmp}{PDMP}{piecewise deterministic Markov processes}

%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
%% \usepackage{lineno}

\journal{NAHS}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for theassociated footnote;
%% use the fnref command within \author or \affiliation for footnotes;
%% use the fntext command for theassociated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for theassociated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \affiliation{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%% \fntext[label3]{}

\title{A Cross-layer Games-in-Games Approach for Robust Control in Hybrid Systems}

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{}
%% \affiliation[label1]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%%
%% \affiliation[label2]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}

\author{Yunian Pan \& Quanyan Zhu} %% Author name

%% Author affiliation
\affiliation{organization={Department of Electrical \& Computer Engineering, New York University}, \\ %Department and Organization
            addressline={370 Jay st},  \\
            city={Brooklyn},
            postcode={11201}, 
            state={NY},
            country={USA}}

%% Abstract
\begin{abstract}
This paper develops a hierarchical ``games-in-games'' control architecture for hybrid systems where continuous-time decision making is coupled with strategic regime switching. We model the system as a regime-switching jump-diffusion process where a fast inner layer solves a robust stochastic game within each mode, while a slow outer layer strategically shapes the transition kernel to induce or mitigate regime shifts. A Dynkin-based analysis decomposes the problem into a hierarchy of value functions satisfying coupled Hamilton-Jacobi-Isaacs (HJI) equations. For the class of Linear-Quadratic and Exponential-Affine games, we prove that this hierarchy collapses into a system of coupled matrix differential equations, enabling semi-closed form solutions via the matrix exponential. We demonstrate the framework's efficacy through a case study on adversarial market microstructure, showing how the outer layer's strategic switching pre-emptively adjusts inner-layer policies against latent regime risks.
\end{abstract}

%%Graphical abstract
%\begin{graphicalabstract}
%\includegraphics{grabs}
%\end{graphicalabstract}

%%Research highlights
% \begin{highlights}
% \item Research highlight 1
% \item Research highlight 2
% \end{highlights}

% %% Keywords
 \begin{keyword}
Regime-Switching Diffusions, Hierarchical Control, Stochastic Differential Games, Hamilton-Jacobi-Isaacs Equations, Coupled Riccati Equations

 \end{keyword}

\end{frontmatter}

%% Add \usepackage{lineno} before \begin{document} and uncomment 
%% following line to enable line numbers
%% \linenumbers

%% main text
%%

%% Use \section commands to start a section
\section{Introduction}

Hybrid systems whose evolution combines continuous dynamics with discrete
mode transitions arise across engineering, economic, and societal domains.
Examples include autonomous infrastructure networks, adaptive manufacturing
systems, multi-vehicle coordination, and regime-switching economic and
financial models.  In these settings, decision-making rarely occurs on a
single timescale or within a single layer of abstraction: slow-timescale
policies shape the discrete evolution of operating modes, while
fast-timescale controllers regulate the continuous state within each mode.
The resulting feedback architecture is inherently multi-layered and
strategic, and requires analytical tools that treat discrete and continuous
components in an integrated fashion.

Existing modeling frameworks illuminate individual components of this
structure.  Piecewise-deterministic Markov processes (PDMPs)
\citep{Davis1984PDMP} offer a rigorous description of systems whose
continuous trajectories are punctuated by mode transitions, and have been
successfully used in queueing, inventory, and reliability applications
\citep{Davis1993Markov,CostaStability1990,CostaStability1999}.  Differential
games and stochastic games \citep{BasarOlsder1999,filar2012competitive}
provide the analytical foundation for adversarial or competitive decision
problems in continuous and discrete time.  However, most classical PDMP
formulations treat jump dynamics as exogenous or subject to a single
controller, while most game-theoretic models do not endow players with the
ability to strategically shape mode transition rates.

This paper develops a unified model that addresses this gap.  We construct a
double-layer hybrid system in which strategic agents select actions that
directly influence the jump intensities of a discrete-mode process, while
the continuous state evolves according to mode-dependent dynamics.  This
structure captures a broad range of applications: cyber-physical security
models in which attack and defense actions modulate network modes
\citep{pasqualetti2013attack,teixeira2015secure}, hierarchical decision
architectures in control and communications
\citep{ahmad2025issues,saad2009hierarchical}, and economic or financial
settings in which higher-level investment or regulatory policies determine
market regimes.

Our contributions are threefold.  
First, we provide a general hybrid-system formulation equipped with mild
assumptions ensuring existence of solutions, moment bounds, and a Dynkin
formula that cleanly separates the contributions of continuous evolution and
mode switching.  
Second, we derive coupled Hamilton-Jacobi equations describing the inner
continuous-time control/game problem and the outer mode-selection problem.
The presentation is intentionally compact: continuity of the value function
is established through a single lemma, followed by two theorems delivering
the Isaacs equation for the continuous layer and the Hamilton-Jacobi
equation for the discrete layer without circular dependencies.  
Third, when specialized to linear dynamics with quadratic costs, the model
reduces to two interacting Riccati families: one associated with the
continuous evolution within each mode, and one associated with the
high-level decision process governing the mode transitions.  This structure
naturally accommodates applications such as mode-aware control design,
hierarchical decision-making, and regime-sensitive financial engineering.

\subsection{Related Work}

\gls{pdmp}s were introduced and formally characterized by \cite{Davis1984PDMP}
as a broad class of non-diffusive stochastic models.  The PDMP framework has
since proven sufficiently general to capture a wide range of applications,
including queueing networks, inventory systems, and reliability analysis
\cite{Davis1993Markov,CostaStability1990,CostaStability1999}.  Classical
treatments typically consider jump dynamics as exogenous, or allow them to
be controlled by a single decision-maker.

In contrast, our model embeds strategic manipulation of the jump kernel
within a game-theoretic layer.  This induces a hybrid decision structure in
which players influence the generator of the PDMP while simultaneously
engaging in continuous-time control or differential-game interactions.
Relevant precedents appear in cyber-physical security models such as
\cite{pasqualetti2013attack,teixeira2015secure}, and in hierarchical
decision formulations including \cite{ahmad2025issues,saad2009hierarchical,anwar2017minimax}.
However, existing hierarchical models do not jointly couple continuous-time
differential games with strategically controlled discrete-mode transitions,
which is the central feature of our formulation.


\section{Problem Formulation}

We consider a hybrid decision architecture in which a continuous state evolves
according to mode-dependent stochastic dynamics, while a discrete mode process switches
between a finite collection of regimes. Two layers of strategic decision-making
interact: a fast-timescale controller/disturbance pair regulating the
continuous state, and a slow-timescale pair of agents whose actions influence
the transition rates among the discrete modes. This structure captures a wide
range of multi-layer hybrid systems, including resilient infrastructure networks,
multi-agent cyber-physical systems, and robust control under regime uncertainty.


Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a complete probability space equipped with a filtration $\mathbb{F} = (\mathcal{F}_t)_{t \ge 0}$ satisfying the usual conditions of right-continuity and completeness. The time horizon is finite, $T < \infty$. 
We define the following primitive stochastic processes adapted to $\mathbb{F}$:
\begin{enumerate}
    \item $W = (W_t)_{t \ge 0}$ is a standard $d$-dimensional Brownian motion.
    \item $N(dt, dz)$ is a Poisson random measure on $[0, T] \times \mathcal{Z}$ with intensity measure $\lambda(dz)dt$, where $\mathcal{Z} \subseteq \mathbb{R}^k$. We denote the compensated measure by $\tilde{N}(dt, dz) = N(dt, dz) - \lambda(dz)dt$.
\end{enumerate}

\begin{definition}[Two-layer hybrid decision system]\label{def:hybrid}
Let $\mathcal{I}=\{1,\dots,N\}$ be a finite set of regimes (modes), $U$ and $W$ compact convex sets representing continuous-layer control and disturbance actions, and
$\mathcal{A}_D$, $\mathcal{A}_A$ finite sets of actions available to the two
agents governing the mode transitions.
A \emph{two-layer hybrid system} is a tuple
\begin{equation*}
    \Gamma =\bigl(\mathcal{X},\,\mathcal{I},\,\mathcal{V},\,\mathcal{W},\,\mathcal{F},\,\mathcal{G}\bigr),
\end{equation*}
where:
\begin{enumerate}
\item $\mathcal{X} \subseteq \mathbb{R}^n$ is the continuous state space and $\mathcal{I}$ is the finite mode space;

\item The continuous-layer policies
\begin{equation*}
\nu:[0,T]\times \mathcal{X}\times \mathcal{I}\to U,\qquad
\omega:[0,T]\times \mathcal{X}\times \mathcal{I}\to W
\end{equation*}
are Borel measurable and $\mathbb{F}$-progressively measurable; the associated admissible policy classes are denoted $\mathcal{V}$ and $\mathcal{W}$;

\item The mode-selection policies
\begin{equation*}
f:[0,T]\times \mathcal{X}\times \mathcal{I}\to \Delta(\mathcal{A}_D),\qquad
g:[0,T]\times \mathcal{X}\times \mathcal{I}\to \Delta(\mathcal{A}_A)
\end{equation*}
assign mixed actions from $\mathcal{A}_D$ and $\mathcal{A}_A$. The admissible classes are denoted $\mathcal{F}$ and $\mathcal{G}$.
\end{enumerate}

Given $(f,g)$ and $(\nu,\omega)$, the hybrid state process $(X_t, I_t)_{t \in [0,T]}$ evolves as a \emph{Regime-Switching Jump-Diffusion} defined by:

\begin{itemize}
\item[(a)] Continuous dynamics: Between jumps of the mode $I_t$, the continuous state $X_t$ evolves according to the stochastic differential equation (SDE):
\begin{align}
dX_t &= f_p\bigl(t, X_t, \nu_t, \omega_t; I_t\bigr)dt
+ \sigma\bigl(t, X_t; I_t\bigr)dW_t \nonumber \\
&\quad + \int_{\mathcal{Z}} \rho (t, X_t, z; I_t) \tilde{N}(dt, dz),
\label{eq:cont-flow}
\end{align}
with $X_0 = x_0 \in \mathcal{X}$. Here, $\nu_t = \nu(t, X_t, I_t)$ and $\omega_t = \omega(t, X_t, I_t)$.

\item[(b)] Discrete dynamics: The mode process $I_t \in \mathcal{I}$ is a controlled continuous-time Markov chain with generator matrix $\Pi_t = [\mu_{ij}(t)]_{i,j \in \mathcal{I}}$ modulated by the outer policies:
\begin{equation}
\mathbb{P}\bigl(I_{t+dt} = j \mid I_t = i, X_t = x\bigr) = \mu_{ij}\bigl(f(t,x,i), g(t,x,i)\bigr)dt + o(dt),
\label{eq:mode-kernel}
\end{equation}
where $\mu_{ii} = - \sum_{j \neq i} \mu_{ij}$. The mode-selection policies $(f,g)$ determine the (possibly time-varying)
regime transition intensities
\begin{equation*}
\mu_{ij}: \Delta(\mathcal{A}_D) \times \Delta(\mathcal{A}_A) \to [0, \infty),
\end{equation*}
yielding the instantaneous rate $\mu_{ij}\bigl(f(t,X_t,I_t),g(t,X_t,I_t)\bigr)$
at each $t$.
\end{itemize}



These dynamics define a probability measure $\mathbb{P}^{\nu,\omega,f,g}$ on the path space $D([0,T]; \mathcal{X} \times \mathcal{I})$.
\end{definition}

The performance of a policy tuple is evaluated through the cost functional:
\begin{equation}
J(f,g;\nu,\omega)
=
\mathbb{E}\!\left[
q_f\bigl(X_T, I_T\bigr)
+
\int_{0}^{T}
c\bigl(t, X_t, \nu_t, \omega_t, I_t\bigr)\,dt
\right].
\label{eq:cost}
\end{equation}

The two-layer decision architecture is expressed as the bi-level optimization
problem
\begin{equation}
    \label{eq:bilevel-problem}
    \begin{aligned}
         & \min _{f \in \mathcal{F}} \max _{g \in \mathcal{G}} \Phi\left(f, g ; \nu^{*}, \omega^{*}\right) \\ & \text { s.t. }  \quad \nu^{*}, \omega^{*} \in \inf _{\nu \in \mathcal{V}} \sup _{\omega \in \mathcal{W}} J(f, g ; \nu, \omega)
    \end{aligned}
\end{equation}

where the inner minimax determines the continuous-layer value and the
outer minimax governs mode manipulation. The functional $\Phi\left(\cdot, \cdot ; \nu^{*}, \omega^{*}\right):  \Delta\left(\mathcal{A}_{D}\right) \times \Delta\left(\mathcal{A}_{A}\right) \rightarrow \mathbb{R}$ represents the outer-layer preference and will be specified
later.



\begin{assumption}[Standing assumptions]\label{assum:regularity}
\begin{itemize}
~
\item[(i)] (\emph{Generalized Isaacs Condition})
For each fixed mode $i \in \mathcal{I}$ and any smooth test function $\phi \in C^2(\mathcal{X})$, we define the generalized Hamiltonian $\mathcal{H}_i[\phi]$ acting on the state $x$, gradient $p = \nabla \phi(x)$, Hessian $M = \nabla^2 \phi(x)$, and controls $(u,w)$:
\begin{align*}
\mathcal{H}_i[\phi](t,x,p,M,u,w) &= c(t,x,u,w,i) + p^\top f_p(t,x,u,w; i) \\
&+ \frac{1}{2}\mathrm{Tr}\bigl(\sigma(t,x; i)\sigma(t,x; i)^\top M\bigr) \\
+ \int_{\mathcal{Z}} \Bigl( \phi(x+\rho (t,x,z; i)) & - \phi(x) - p^\top\rho (t,x,z; i) \Bigr) \nu(dz; u,w).
\end{align*}
We assume that the minimax condition holds for all valid inputs:
\begin{equation*}
\min_{u\in U}\max_{w\in W}\mathcal{H}_i[\phi](t,x,p,M,u,w) = \max_{w\in W}\min_{u\in U}\mathcal{H}_i[\phi](t,x,p,M,u,w).
\end{equation*}

\item[(ii)] The coefficients $f_p, \sigma, \rho $ satisfy the standard Lipschitz and linear growth conditions in $x$, uniformly in $(u,w)$. The measure $\nu(dz; u,w)$ is a bounded kernel satisfying appropriate integrability conditions. The costs $c, q_f$ satisfy quadratic growth conditions.
\end{itemize}
\end{assumption}

\begin{lemma}[Existence and Estimates]\label{lem:existence}
Under Assumption~\ref{assum:regularity}, for any admissible policies, the hybrid system \eqref{eq:cont-flow}--\eqref{eq:mode-kernel} admits a unique strong solution $(X_t, I_t)_{t \in [0,T]}$. Furthermore, for any $p \ge 1$, there exists a constant $C_p > 0$ such that:
\begin{equation*}
\mathbb{E}\left[\sup_{t\in[0,T]} \|X_t\|^p\right] \le C_p\bigl(1+\|x_0\|^p\bigr).
\end{equation*}
\end{lemma}

\begin{proof}
Since the transition rates are bounded, the mode process $I_t$ undergoes finitely many jumps in $[0, T]$ almost surely. Between any two jump times, the system evolves as a standard SDE with jumps. Under the Lipschitz and linear growth conditions (Assumption~\ref{assum:regularity}), a unique strong solution exists for each interval (see e.g., \citep{applebaum2009levy, oksendal2005stochastic}). We construct the global solution $(X_t)_{t\ge0}$ by concatenating these trajectory segments at the jump times of $I_t$.

We apply It\^o's formula to the function $\phi(x) = \|x\|^p$. The linear growth assumption on the drift $f_p$ and jump intensity implies that the generator is bounded by $\mathcal{L}\phi(x) \le C(1 + \|x\|^p)$.
To bound the expectation of the supremum, we handle the martingale terms (diffusion and compensated jumps) using the {Burkholder-Davis-Gundy (BDG) inequalities}, which control the maximum of the stochastic integrals.
Combining these bounds yields an integral inequality for $g(t) = \mathbb{E}[\sup_{s \le t} \|X_s\|^p]$. The final result follows immediately from {Gr\"onwall's inequality}.
\end{proof}

% \begin{proof}
% \textit{Step 1: Existence and Uniqueness.}
% Let $0 = T_0 < T_1 < \dots < T_k < \dots$ denote the jump times of the mode process $I_t$. Since the transition rates $\mu_{ij}$ are bounded, $I_t$ is non-explosive almost surely, i.e., $T_k \to \infty$ as $k \to \infty$.
% On each random interval $[T_k, T_{k+1})$, the mode $I_t = i$ is constant. The dynamics of $X_t$ reduce to a standard SDE with jumps driven by Brownian motion $W_t$ and Poisson measure $N$. Under Assumption~\ref{assum:regularity}(ii), the coefficients $f_p, \sigma, \rho $ satisfy Lipschitz continuity and linear growth conditions.
% Classic results for L\'evy-type SDEs (e.g., Theorem 6.2.3 in \cite{applebaum2009levy} or \cite{oksendal2005stochastic}) guarantee the existence of a unique strong solution $X_t^{(k)}$ on $[T_k, T_{k+1})$ starting from $X_{T_k}$. We construct the global solution $X_t$ by concatenating these trajectory segments: $X_t = X_t^{(k)}$ for $t \in [T_k, T_{k+1})$. The resulting process is c\`adl\`ag and adapted to $\mathbb{F}$.

% \textit{Step 2: Moment Estimates.}
% We prove the bound for $p \ge 2$ (the case $1 \le p < 2$ follows by Jensen's inequality).
% Apply It\^o's formula to the function $V(x) = \|x\|^p$. For the Jump-Diffusion process \eqref{eq:cont-flow}, the differential takes the form:
% \begin{align*}
% d\|X_t\|^p &= \mathcal{L}V(X_t) dt + p\|X_t\|^{p-2} X_t^\top \sigma dW_t \\
% &\quad + \int_{\mathcal{Z}} \left( \|X_t + \rho \|^p - \|X_t\|^p \right) \tilde{N}(dt, dz),
% \end{align*}
% where $\mathcal{L}$ is the infinitesimal generator including drift, diffusion correction, and the compensator for the jump term.
% Using the linear growth condition (Assumption~\ref{assum:regularity}(ii)), we bound the generator term by $\mathcal{L}V(x) \le C(1 + \|x\|^p)$.
% Integrating from $0$ to $t$ and taking the supremum inside the expectation:
% \begin{equation*}
% \mathbb{E}\left[\sup_{s \le t} \|X_s\|^p\right] \le C \left( 1 + \|x_0\|^p + \int_0^t \mathbb{E}\left[\sup_{r \le s} \|X_r\|^p\right] ds \right) + \mathcal{M}_t,
% \end{equation*}
% where $\mathcal{M}_t$ represents the contribution of the local martingale terms (diffusion and compensated jumps).
% To bound $\mathcal{M}_t$, we employ the \textbf{Burkholder-Davis-Gundy (BDG) inequalities}, which bound the supremum of stochastic integrals by their quadratic variation:
% \begin{equation*}
% \mathbb{E}\left[\sup_{s \le t} \left| \int_0^s p\|X_r\|^{p-2}X_r^\top \sigma dW_r \right| \right] \le C_p \mathbb{E}\left[ \left( \int_0^t \|X_s\|^{2p-2} \|\sigma\|^2 ds \right)^{1/2} \right].
% \end{equation*}
% Using the linear growth of $\sigma$ and Young's inequality, this term is absorbed into the integral of the moment $\mathbb{E}[\|X_s\|^p]$. A similar estimate applies to the jump martingale using the BDG inequality for discontinuous martingales \citep[Sec 4.4]{applebaum2009levy}.
% Combining these estimates yields an integral inequality of the form:
% \begin{equation*}
% \phi(t) \le C_1 + C_2 \int_0^t \phi(s) ds, \quad \text{where } \phi(t) = \mathbb{E}\left[\sup_{s \le t} \|X_s\|^p\right].
% \end{equation*}
% The final result follows immediately from \textbf{Gr\"onwall's Lemma}.
% \end{proof}


\section{Cross-Layer Viscosity Solution}

Once the hybrid architecture $\Gamma$ in Definition~\ref{def:hybrid} is equipped
with Assumption~\ref{assum:regularity}, the coupled state process
$(X_t, I_t)$ is a Regime-Switching Jump-Diffusion. Between jumps of the discrete mode $I_t$, the
continuous state $X_t$ follows the stochastic evolution generated by the drift $f_p$, diffusion $\sigma$,
and jump measure defined in \eqref{eq:cont-flow}. 
For any probe function
\begin{equation*}
\phi:\mathcal{X}\times \mathcal{I}\times[0,T]\to\mathbb{R},\qquad
\phi(\cdot, i, \cdot) \in C^{2,1}(\mathcal{X} \times [0,T]),
\end{equation*}
the infinitesimal generator of $(X_t, I_t)$ under continuous-layer policies
$(\nu,\omega)$ and mode-selection policies $(f,g)$ is given by the sum of the
diffusion generator, the inner jump generator, and the regime-switching operator:
\begin{equation}
\label{eq:generator-full}
\begin{aligned}
(\mathcal{L}^{f,g,\nu,\omega}\phi)(t,x,i)
&=
\frac{\partial \phi}{\partial t}(t,x,i)
+ \nabla_x\phi(t,x,i)^{\top} f_p\bigl(t,x,\nu,\omega;i\bigr) \\
&\quad
+ \frac{1}{2}\mathrm{Tr}\Bigl(\sigma(t,x;i)\sigma(t,x;i)^\top \nabla^2_{xx}\phi(t,x,i)\Bigr) \\
+ \int_{\mathcal{Z}} \Bigl( &\phi(t, x+\rho (t,x,z; i), i) - \phi(t,x,i) - \nabla_x\phi^\top \rho (t,x,z; i) \Bigr) \nu(dz) \\
&\quad
+ \sum_{j\neq i}
    \mu_{ij}\bigl(f(t,x,i),g(t,x,i)\bigr)
    \bigl[\phi(t,x,j)-\phi(t,x,i)\bigr].
\end{aligned}
\end{equation}
Because $(f,g)$ may depend explicitly on time and on the instantaneous
continuous state, the generator~\eqref{eq:generator-full} captures the full
state-time dependence of the mode-switching rates.

\begin{lemma}[Dynkin identity]
\label{lem:dynkin}
Under Assumption~\ref{assum:regularity} and fixed admissible policies
$(f,g,\nu,\omega)$, the process
\begin{equation*}
M_\phi(\tau)
=
\phi\bigl(\tau, X_\tau, I_\tau\bigr)
-
\phi(t, x, i)
-
\int_t^\tau
\bigl(\mathcal{L}^{f,g,\nu,\omega}\phi\bigr)(s, X_s, I_s)\,ds
\end{equation*}
is a local martingale. If $\phi$ and its derivatives are bounded, it is a martingale for any bounded stopping time $\tau\le T$. Consequently,
\begin{equation}
\label{eq:dynkin}
\mathbb{E}\bigl[\phi(\tau, X_\tau, I_\tau)\bigr]
=
\phi(t, x, i)
+
\mathbb{E}
\int_t^\tau
\bigl(\mathcal{L}^{f,g,\nu,\omega}\phi\bigr)(s, X_s, I_s)\,ds.
\end{equation}
\end{lemma}

\begin{proof}
Let $(T_k)_{k\ge 0}$ denote the jump times of the mode process $I_t$ with $T_0=t$.
On each random interval $[T_k, T_{k+1})$, the mode $I_t=i$ remains constant.
The evolution of $\phi(t, X_t, i)$ is governed by It\^o's formula for semimartingales with jumps \citep[Thm 4.4.7]{applebaum2009levy}:
\begin{equation*}
\phi(T_{k+1}^-, X_{T_{k+1}^-}, i) - \phi(T_k, X_{T_k}, i)
= \int_{T_k}^{T_{k+1}} \mathcal{L}_{inner} \phi \, ds + \mathcal{M}_{k, k+1},
\end{equation*}
where $\mathcal{L}_{inner}$ represents the continuous drift, diffusion, and inner jump parts of the generator, and $\mathcal{M}_{k, k+1}$ collects the stochastic integrals with respect to $dW_t$ and $\tilde{N}(dt, dz)$, which are zero-mean martingales under the boundedness assumptions.

At the jump time $T_{k+1}$, the mode switches from $i$ to $j$ with intensity $\mu_{ij}$. The compensator for this discrete transition is exactly the regime-switching sum in \eqref{eq:generator-full}. Summing these contributions over all intervals up to $\tau$ and taking expectations eliminates the martingale terms, yielding the claimed identity.
\end{proof}

Lemma~\ref{lem:dynkin} connects the stochastic dynamics in
Definition~\ref{def:hybrid} to the value functions developed below. It
justifies infinitesimal expansions of probe functions and supports the
viscosity-solution formulations of the coupled Hamilton-Jacobi-Isaacs (HJI)
equations \citep{pham2009continuous}.

\subsection{Inner-Layer Hamilton-Jacobi-Isaacs Equation}
\label{sec:inner-HJI}

Definition~\ref{def:hybrid} shows that once the mode-selection policies
$(f,g)$ are frozen, the continuous-layer control and disturbance interact
through a zero-sum stochastic differential game. The state evolves as a controlled Jump-Diffusion, coupled with mode-dependent switching intensities.

For fixed $(f,g)$, define the inner-layer value functions by
\begin{equation}
\label{eq:Vi}
\begin{aligned}
V_i(x,t;f,g)
&=
\inf_{\nu\in\mathcal{V}}
\sup_{\omega\in\mathcal{W}}
\mathbb{E}
\bigg[
\int_t^{T}
c\bigl(s, X_s, \nu_s, \omega_s, I_s\bigr) ds 
+
c_T\bigl(X_T, I_T\bigr)
\big|
\mathcal{F}_t
\bigg].
\end{aligned}
\end{equation}

\begin{lemma}[Inner-layer HJI]
\label{lem:inner-HJI}
For fixed mode-selection policies $(f,g)$, the family of inner-layer value
functions $\{V_i(\cdot,\cdot;f,g)\}_{i\in \mathcal{I}}$ is the unique
viscosity solution (with appropriate growth conditions) of the following system of Partial Integro-Differential Equations (PIDE):
\begin{equation}
\label{eq:HJI-inner}
\begin{aligned}
-\partial_t V_i(t,x)
&=
\min_{u\in U}\max_{w\in W}
\Bigl\{
c(t,x,u,w,i)
+ \mathcal{L}^{u,w}_i V_i(t,x) \\
&\quad
+ \sum_{j\neq i}
\mu_{ij}\bigl(f(t,x,i),g(t,x,i)\bigr)
\bigl[V_j(t,x)-V_i(t,x)\bigr]
\Bigr\}, \\
V_i(T,x)&=c_T(x,i),
\end{aligned}
\end{equation}
for all $(t,x)\in [0,T]\times \mathcal{X}$.
Here, $\mathcal{L}^{u,w}_i$ is the local integro-differential operator:
\begin{align*}
\mathcal{L}^{u,w}_i \phi(x) &= \nabla_x \phi(x)^\top f_p(t,x,u,w; i) \\
&+ \frac{1}{2}\mathrm{Tr}\bigl(\sigma(t,x; i)\sigma(t,x; i)^\top \nabla^2_{xx}\phi(x)\bigr) \\
&+ \int_{\mathcal{Z}} \Bigl(\phi(x+\rho (t,x,z; i)) - \phi(x) - \nabla_x\phi(x)^\top \rho (t,x,z; i)\Bigr) \nu(dz).
\end{align*}
\end{lemma}

\begin{proof}
We proceed in two steps: first establishing that the value function $V_i$ is a viscosity solution (satisfying the subsolution and supersolution properties), and second invoking a comparison principle for uniqueness.

We only demonstrate the subsolution property as the supersolution argument is symmetric. Let $\phi(t,x) \in C^{1,2}([0,T]\times \mathcal{X})$ be a smooth test function such that $V_i(t,x) - \phi(t,x)$ achieves a local maximum at $(\hat{t}, \hat{x})$ with $V_i(\hat{t}, \hat{x}) = \phi(\hat{t}, \hat{x})$.

From the Dynamic Programming Principle (DPP), for small $h > 0$:
\begin{equation*}
V_i(\hat{t}, \hat{x}) \le \inf_{\nu} \sup_{\omega} \mathbb{E} \left[ \int_{\hat{t}}^{\hat{t}+h} c(s, X_s, \nu_s, \omega_s, i) ds + V_{I_{\hat{t}+h}}(\hat{t}+h, X_{\hat{t}+h}) \right].
\end{equation*}

We decompose the expectation based on whether the mode $I_s$ jumps during $[\hat{t}, \hat{t}+h]$.
 With probability $1 - O(h)$, no jump occurs. In this case, $I_{\hat{t}+h}=i$. Using $V_i \le \phi$ and applying It\^o's formula to $\phi$:
$ \mathbb{E}[\phi(\hat{t}+h, X_{\hat{t}+h}) - \phi(\hat{t}, \hat{x})] = \mathbb{E}\int_{\hat{t}}^{\hat{t}+h} (\partial_t \phi + \mathcal{L}^{u,w}_i \phi) ds.$
With probability rate $\mu_{ij}(f,g)$, the mode switches to $j$. The contribution to the expected value change is dominated by the difference $V_j - V_i \approx V_j - \phi$, the jump contribution is then:$
     \int_{\hat{t}}^{\hat{t}+h} \sum_{j \ne i} \mu_{ij}(f,g) [V_j(s, X_s) - \phi(s, X_s)] ds + o(h).$

Substituting these expansions back into the DPP inequality and using $V_i(\hat{t}, \hat{x}) = \phi(\hat{t}, \hat{x})$ to cancel the zero-order terms:
\begin{equation*}
0 \le \inf_{\nu} \sup_{\omega} \mathbb{E} \left[ \int_{\hat{t}}^{\hat{t}+h} \left( c + \partial_t \phi + \mathcal{L}^{u,w}_i \phi + \sum_{j \ne i} \mu_{ij}(f,g) [V_j - \phi] \right) ds \right] + o(h).
\end{equation*}
Dividing by $h$ and letting $h \downarrow 0$, the mean value theorem applies. Since the inequality holds for all controls, we obtain:
\begin{equation*}
-\partial_t \phi(\hat{t}, \hat{x}) - \inf_{u} \sup_{w} \left\{ c + \mathcal{L}^{u,w}_i \phi \right\} - \sum_{j \ne i} \mu_{ij}(f,g) [V_j(\hat{t},\hat{x}) - V_i(\hat{t},\hat{x})] \le 0.
\end{equation*}
This confirms the viscosity subsolution condition. The supersolution argument is symmetric using a local minimum.

The system \eqref{eq:HJI-inner} is a system of coupled non-linear PIDEs. Under Assumption~\ref{assum:regularity} (Lipschitz coefficients, quadratic growth), the comparison principle for viscosity solutions of such systems holds \citep[Thm 3.4]{barles1997backward}. Specifically, if $U$ is a subsolution and $V$ is a supersolution with $U(T) \le V(T)$, then $U \le V$ on $[0,T]$. Since our value function is both, it is the unique solution.
\end{proof}
The family $\{V_i\}$ encodes the inner-layer response to any fixed choice of
mode-selection strategies $(f,g)$. In particular, $V_i(x,t;f,g)$ can be
regarded as the effective performance index associated with starting in mode
$i$ at state $x$ and time $t$, factoring in the optimal continuous-time response to the induced regime uncertainty.


\subsection{Outer-Layer Hamilton-Jacobi-Isaacs System}
\label{sec:outer-HJI}

We now return to the outer-level problem~\eqref{eq:bilevel-problem}, in which
the two mode-selection agents choose strategies $(f,g)$ that influence the
mode-transition dynamics while anticipating the optimal inner-layer responses
captured by Lemma~\ref{lem:inner-HJI}.

For each fixed pair of mode-selection policies $(f,g)$, the inner-layer value
functions $V_i(\cdot,\cdot;f,g)$ are determined by the system~\eqref{eq:HJI-inner}.
Let the optimal inner feedback policies be denoted by:
\begin{equation*}
(u^{*,f,g}, w^{*,f,g})(t,x,i) \in \arg \min_{u\in U}\max_{w\in W} 
\mathcal{H}_i[V_i](t, x, \nabla_x V_i, \nabla^2 V_i, u, w)
\end{equation*}
Define the corresponding \emph{closed-loop coefficients}:
\begin{align}
\label{eq:closed-loop-drift}
\bar f_p(t,x,i; f,g) &:= f_p\bigl(t,x, u^{*,f,g}, w^{*,f,g}; i\bigr), \nonumber \\
\bar \sigma(t,x,i; f,g) &:= \sigma\bigl(t,x; i\bigr), \nonumber \\
\bar \nu(dz; t,x,i, f,g) &:= \nu(dz; u^{*,f,g}, w^{*,f,g}).
\end{align}
Under $(f,g)$, the hybrid state $(X_t, I_t)$ therefore evolves as a Jump-Diffusion driven by these effective coefficients, coupled with the regime transition rates $\mu_{ij}(f,g)$.



We model the outer-layer objective as a path integral whose running cost
depends on the inner-layer value functions. Let
\begin{equation*}
\varphi : [0,T]\times\mathcal{X}\times \mathcal{I} \times \mathbb{R} \to \mathbb{R}
\end{equation*}
denote a bounded, continuous outer-layer running cost, where the final
argument will be instantiated with the scalar quantity
$V_i(t,x;f,g)$.

For an initial condition $(t,x,i)$ and mode-selection policies $(f,g)$, define
the outer-layer performance functional
\begin{equation}
\label{eq:outer-cost-functional}
\begin{aligned}
J_{\mathrm{out}}(t,x,i;f,g)
:=
\mathbb{E}^{t,x,i}_{f,g}
\Bigl[
  \int_t^{T}
    \varphi\bigl(s, X_s, I_s,
    V_{I_s}(s, X_s; f,g)\bigr) ds
  + c_T\bigl(X_T, I_T\bigr)
\Bigr],
\end{aligned}
\end{equation}
where $\mathbb{E}^{t,x,i}_{f,g}$ denotes expectation with respect to the
probability law induced by the closed-loop Jump-Diffusion dynamics and the transition rates $\mu_{ij}(f,g)$.

The outer-layer value functions are then
\begin{equation}
\label{eq:outer-value-function}
U_i(t,x)
:=
\inf_{f\in\mathcal{F}}\sup_{g\in\mathcal{G}}
J_{\mathrm{out}}(t,x,i;f,g).
\end{equation}


\subsubsection*{Outer-layer Isaacs condition and HJI system}
We impose an Isaacs condition at the outer layer.

\begin{assumption}[Outer-layer Isaacs condition]
\label{ass:outer-isaacs}
For each tuple $(t,x,i)$ and test function $\psi$, consider the outer-layer Hamiltonian
\begin{align}
\label{eq:outer-hamiltonian}
\mathcal{H}_{\mathrm{out}}[\psi](t,x,i,\alpha,\beta)
:=\;&
\varphi\bigl(t,x,i,V_i^{\alpha,\beta}(t,x)\bigr)
+ \mathcal{L}^{\alpha,\beta}_{eff} \psi(x) \nonumber \\
&+ \sum_{j\neq i}\mu_{ij}(\alpha,\beta)\bigl[\psi(t,x,j) - \psi(t,x,i)\bigr],
\end{align}
where $\mathcal{L}^{\alpha,\beta}_{eff}$ is the generator associated with the closed-loop coefficients $\bar f_p, \bar \sigma, \bar \nu$ defined in \eqref{eq:closed-loop-drift} (evaluated at mixed actions $\alpha, \beta$). We assume that the minimax condition holds:
\begin{equation}
\label{eq:outer-isaacs}
\inf_{\alpha\in\Delta(\mathcal{A}_D)}
  \sup_{\beta\in\Delta(\mathcal{A}_A)}
  \mathcal{H}_{\mathrm{out}} =
\sup_{\beta\in\Delta(\mathcal{A}_A)}
  \inf_{\alpha\in\Delta(\mathcal{A}_D)}
  \mathcal{H}_{\mathrm{out}}.
\end{equation}
\end{assumption}

Under Assumption~\ref{ass:outer-isaacs} and the regularity inherited from
Assumption~\ref{assum:regularity}, the outer-layer value functions satisfy the
following system of HJI equations.

\begin{lemma}[Outer-layer HJI]
\label{lem:outer-HJI}
For each $i\in \mathcal{I}$, the outer-layer value function $U_i$ is the unique
viscosity solution of
\begin{equation}
\label{eq:HJI-outer}
\begin{aligned}
-\partial_t U_i(t,x)
&=
\inf_{\alpha\in\Delta(\mathcal{A}_D)}
 \sup_{\beta\in\Delta(\mathcal{A}_A)}
\Bigl\{
\varphi\bigl(t,x,i,V_i^{\alpha,\beta}(t,x)\bigr) \\
&
+ \mathcal{L}^{\alpha,\beta}_{eff} U_i(t,x)
+ \sum_{j\neq i}
\mu_{ij}(\alpha,\beta)
\bigl[U_j(t,x) - U_i(t,x)\bigr]
\Bigr\}, \\
U_i(T,x)
&=
c_T(x,i),
\end{aligned}
\end{equation}
for all $(t,x)\in[0,T]\times\mathcal{X}$.
\end{lemma}
The proof follows the same argument as Lemma~\ref{lem:inner-HJI}. We observe that the outer optimization problem~\eqref{eq:outer-value-function} is a generalized Bolza problem for a Regime-Switching Jump-Diffusion, where the drift, diffusion, and jump measure are determined by the closed-loop coefficients $\bar f_p, \bar \sigma, \bar \nu$.

Under Assumption~\ref{assum:regularity}(iii) (strict convex-concavity of the inner Hamiltonian), the inner feedback maps $(u^{*,f,g}, w^{*,f,g})$ are continuous with respect to the gradient $\nabla_x V_i$ \citep{bardi2008optimal}. Although $\nabla_x V_i$ exists only in the generalized viscosity sense, the effective outer dynamics satisfy the necessary growth and continuity conditions to apply the standard dynamic programming principle.
Consequently, $U_i$ is characterized as the unique viscosity solution to \eqref{eq:HJI-outer} via the same expansion of the Dynkin identity employed in Lemma~\ref{lem:inner-HJI}.
Thus the outer-layer HJI system~\eqref{eq:HJI-outer} mirrors the
``generator-plus-minimax'' structure of the inner-layer HJI
\eqref{eq:HJI-inner}, but with effective dynamics that incorporate the optimal inner-layer response.


\section{Case Study: Mode-Controlled Markov Jump Linear System}

We now examine the important case in which the inner-layer differential game
admits closed-form solutions. We focus on the \emph{Linear-Quadratic-Gaussian (LQG)} setting without stochastic inner-layer jump, which yields a coupled family of matrix Riccati equations.

Fix a mode $i\in \mathcal{I}$, and assume the continuous state evolves as a linear SDE controlled by affine drifts:
\begin{equation*}
dX_t
=
(A_i X_t + B_i u + D_i w)dt + \Sigma_i dW_t,
\end{equation*}
where $\Sigma_i \Sigma_i^\top \succ 0$ captures the regime-dependent volatility. The running and terminal costs are quadratic:
\begin{equation*}
\begin{aligned}
c(t,x,u,w,i)
&=
x^\top Q_i x
+ u^\top R_i u
- w^\top S_i w, \\
c_T(x,i)
&=
x^\top Q_{T,i} x,
\end{aligned}
\end{equation*}
with $Q_i\succeq 0$, $R_i\succ 0$, and $S_i\succ 0$.
Under these conditions, the Generalized Isaacs Condition (Assumption~\ref{assum:regularity}) holds. Although the diffusion adds a constant trace term to the Hamiltonian, the saddle-point feedback $(u_i^*,w_i^*)$ remains unique and affine in the gradient $\nabla_x V_i$:
\begin{equation*}
\begin{aligned}
u_i^*(t,x)
&=
- R_i^{-1} B_i^\top \nabla_x V_i(x,t;f,g), \\
w_i^*(t,x)
&=
S_i^{-1} D_i^\top \nabla_x V_i(x,t;f,g).
\end{aligned}
\end{equation*}

Substituting these into the inner-layer HJI~\eqref{eq:HJI-inner} yields the Stochastic LQ-specialized HJI:
\begin{equation}
\label{eq:HJI-LQ-inner}
\begin{aligned}
-\partial_t V_i
&=
x^\top Q_i x
- \nabla_x V_i^\top B_i R_i^{-1} B_i^\top \nabla_x V_i \\
&\quad
+ \nabla_x V_i^\top D_i S_i^{-1} D_i^\top \nabla_x V_i
+ \nabla_x V_i^\top A_i x \\
&\quad
+ \frac{1}{2}\mathrm{Tr}(\Sigma_i \Sigma_i^\top \nabla^2_{xx} V_i)
+ \sum_{j\neq i} \mu_{ij}(f,g)
    \bigl[V_j-V_i\bigr].
\end{aligned}
\end{equation}

We adopt the quadratic ansatz $V_i(t,x) = x^\top P_i(t) x + r_i(t)$. The second-order term $\nabla^2_{xx} V_i = 2P_i(t)$ results in a trace term that decouples from the quadratic optimization. Consequently, the quadratic weight matrices $\{P_i\}_{i\in \mathcal{I}}$ satisfy the \emph{Coupled Riccati Differential Equations}:
\begin{equation}
\label{eq:coupled-Riccati}
\begin{aligned}
-\dot P_i
&=
Q_i
+ A_i^\top P_i + P_i A_i
- P_i B_i R_i^{-1} B_i^\top P_i \\
&\quad
+ P_i D_i S_i^{-1} D_i^\top P_i
+ \sum_{j\neq i} \mu_{ij}(f,g)\bigl(P_j - P_i\bigr),
\end{aligned}
\end{equation}
with boundary condition $P_i(T) = Q_{T,i},$
for $i\in \mathcal{I}$. Note that while the stochastic noise affects the scalar offset $r_i(t)$, the feedback control gain depends only on $P_i(t)$, which is robust to the additive noise.

\subsection{Hierarchical Solution and Outer-Layer Structure}

To analyze the outer layer, we can exploit the time-scale separation or treat the inner value matrices $P_i(t)$ as state variables for the outer game.
Substituting the inner quadratic form $V_i^0(t,x) = x^\top P_i(t) x$ into the outer HJI \eqref{eq:HJI-outer} yields a matrix-valued minimax ODE system for the outer-layer matrices $\{K_i(t)\}_{i \in \mathcal{I}}$:
\begin{equation*}
-\dot K_i
=
\min_{f}\max_{g}
\Bigl\{
Q^{P}_i(t)
+
\sum_{j\neq i}\mu_{ij}(f,g)\bigl(K_j - K_i\bigr)
\Bigr\},
\end{equation*}
with $K_i(T)=Q_{T,i}$. Here, $Q^{P}_i(t)$ represents the effective running cost derived from the inner layer's current risk-adjusted value $P_i(t)$.

\begin{remark}[Well-Posedness of the Matrix Minimax]
The matrix-valued minimax operation in the ODE is defined with respect to the cone of positive semidefinite matrices ($\mathbb{S}^n_+$). If the difference $\Delta K_{ij}(t)$ is indefinite, the optimal outer policy depends on the state direction $x$. However, if the modes satisfy a global monotonicity property (e.g., $K_j(t) \succeq K_i(t)$ as guaranteed by Proposition~\ref{prop:monotonicity} for hardened modes), the matrix difference is definite. In this case, the optimal strategies $(f^*, g^*)$ become state-independent, allowing the outer value function to remain strictly quadratic and the Riccati system to be solved offline.
\end{remark}

While this system defines the value functions implicitly, we can derive explicit structural properties of the optimal mode-selection strategies by assuming the transition rates are affine in the players' actions.

\begin{assumption}[Affine Control of Rates]
\label{ass:affine-rates}
The transition intensity from mode $i$ to $j$ is given by:
\begin{equation*}
\mu_{ij}(f,g) = \bar{\mu}_{ij} + \sum_{k \in \mathcal{A}_D} f_k \lambda_{ij}^{(D,k)} + \sum_{l \in \mathcal{A}_A} g_l \lambda_{ij}^{(A,l)},
\end{equation*}
where $\bar{\mu}_{ij}$ is the base rate, and $\lambda_{ij}^{(\cdot)}$ represents the sensitivity of the transition to specific discrete actions.
\end{assumption}

Under Assumption~\ref{ass:affine-rates}, provided the inner state $P_i(t)$ is treated as fixed at time $t$ (consistent with the coupled dynamics \eqref{eq:coupled-Riccati}), the outer Hamiltonian becomes linear in the probability vectors $f$ and $g$. Consequently, the optimal policies are \emph{Bang-Bang} (switching between pure strategies).

\begin{proposition}[Bang-Bang Structure of Regime Switching]
Let $\Delta K_{ij}(t) = K_j(t) - K_i(t)$ denote the matrix-valued ``gain'' of switching from mode $i$ to $j$. The optimal outer policies $(f^*, g^*)$ are determined by:
\begin{align*}
f^*(t) &\in \arg\min_{f \in \Delta(\mathcal{A}_D)} \sum_{j \neq i} \left( \sum_{k} f_k \lambda_{ij}^{(D,k)} \right) x^\top \Delta K_{ij}(t) x, \\
g^*(t) &\in \arg\max_{g \in \Delta(\mathcal{A}_A)} \sum_{j \neq i} \left( \sum_{l} g_l \lambda_{ij}^{(A,l)} \right) x^\top \Delta K_{ij}(t) x.
\end{align*}
\end{proposition}

This explicit characterization reveals that the macro-players act as \emph{switched controllers}: they monitor the ``energy difference'' $x^\top \Delta K_{ij}(t) x$ between regimes. When this difference crosses a critical threshold defined by the sensitivity parameters $\lambda$, the agents instantaneously switch their preferred transition matrix to minimize (or maximize) the future quadratic cost.

\subsection{Coupled Riccati Flows and Mode Hardening}

Define the block operator
$\mathcal{R}:(\mathbb{S}^n)^S\to(\mathbb{S}^n)^S$ by
\begin{equation*}
\bigl(\mathcal{R}(\mathbf{P})\bigr)_i
=
A_i^\top P_i + P_i A_i + Q_i
- P_i B_i R_i^{-1} B_i^\top P_i
+ P_i D_i S_i^{-1} D_i^\top P_i,
\end{equation*}
and the coupling operator
\begin{equation*}
(M\mathbf{P})_i
=
\sum_{j\neq i}\mu_{ij}^*\bigl(P_j - P_i\bigr),
\end{equation*}
where $\mu_{ij}^*$ denotes a fixed (e.g., stationary) choice of transition
rates.  The coupled Riccati equations \eqref{eq:coupled-Riccati} can then be
written compactly as
\begin{equation*}
-\dot{\mathbf{P}}
=
\mathcal{R}(\mathbf{P}) + M\mathbf{P},
\qquad
-\dot{\mathbf{K}}
=
\mathbf{Q}(t) + M\mathbf{K},
\end{equation*}
where $\mathbf{P}=(P_i)_{i\in S}$, $\mathbf{K}=(K_i)_{i\in S}$, and
$\mathbf{Q}(t)=(Q^{f,g}_i(t))_{i\in S}$.  The stacked view makes it clear
that $M$ acts as a diffusive coupling across modes, while $\mathcal{R}$
captures the intra-mode LQ behavior.

Suppose each pair $(A_i,B_i)$ is stabilizable, each pair
$(A_i,Q_i^{1/2})$ is detectable, and the matrix $M$ is irreducible with
nonnegative off-diagonal entries.  Then the stacked system
\begin{equation*}
-\dot{\mathbf{P}}
=
\mathcal{R}(\mathbf{P}) + M\mathbf{P},
\qquad
\mathbf{P}(T)=\mathbf{Q}_T,
\end{equation*}
admits a unique solution on $[0,T]$ satisfying $P_i(t)\succeq 0$ for all
$t$ and $i$.

This follows because $\mathcal{R}$ is locally Lipschitz on
$(\mathbb{S}_+^n)^S$ and preserves positive semidefiniteness by standard
Riccati comparison arguments, while the coupling term $M\mathbf{P}$ is a
Metzler operator that generates a contraction on the cone
$(\mathbb{S}_+^n)^S$.  Existence and uniqueness follow from Picard
iteration applied backward in time.  The same reasoning applies to
$\mathbf{K}$, since the minimax operator does not destroy Lipschitz
continuity.

\begin{proposition}[Monotonicity with respect to mode hardening]
\label{prop:monotonicity}
Let $M^{(1)}$ and $M^{(2)}$ correspond to two stationary outer-layer
policies with the same terminal data.  Suppose that, for transitions into a
given collection of ``unfavorable'' modes (for example, degraded operating
regimes in a security or reliability application), the coupling matrices
satisfy $M^{(1)}\preceq M^{(2)}$ componentwise.  Then the associated
Riccati stacks satisfy
\begin{equation*}
P_i^{(1)}(t)\preceq P_i^{(2)}(t)
\qquad \text{for all } t\in[0,T],\; i\in S.
\end{equation*}
\end{proposition}

\begin{proof}
For each $i$, the difference
$\Delta_i(t)=P_i^{(2)}(t)-P_i^{(1)}(t)$ satisfies a linear matrix
differential inequality driven by $(M^{(2)}-M^{(1)})\mathbf{P}^{(2)}$.  Since
$M^{(2)}-M^{(1)}$ has nonnegative off-diagonal entries, the cooperative
system comparison theorem for matrix-cone flows \citep{costa2006jump}
implies $\Delta_i(t)\succeq 0$ on $[0,T]$ for all $i$.
\end{proof}

In applications, policies that reduce transition rates into unfavorable modes
or increase rates into favorable modes can be interpreted as
\emph{hardening} interventions.  Proposition~\ref{prop:monotonicity} shows
that such hardening leads to an ordering of the coupled Riccati solutions,
and hence of the associated quadratic value functions.  In particular, this
provides a structural way to quantify the impact of mode-hardening actions
(e.g., cyber hardening in networked systems, regulatory interventions in
financial markets) on the hybrid LQ performance indices.  These Riccati flows
can be integrated numerically by standard backward schemes; in our case study
we rely on their well-posedness to synthesize feedback policies.



\section{Application: Cross-layer Avellaneda-Stoikov Game }\label{sec:case}

To demonstrate the efficacy of the games-in-games architecture, we apply the framework to a high-frequency market making problem under regime uncertainty. We extend the classic Avellaneda-Stoikov (AS) inventory management model \citep{avellaneda2008high} to a hierarchical setting where:
1.  The inner layer is a zero-sum differential game between a \textit{Market Maker} (MM) and a \textit{Strategic Predator}  (SP) who exerts adversarial pressure on the price drift.
2.  The outer layer is a game between a \textit{Macro-Attacker} (seeking to induce crisis regimes) and a \textit{Stabilizer} (seeking to maintain market calm).

\subsection{Market Dynamics \& Game Formulation}

Let the market operate in one of $N$ regimes, $I_t \in \mathcal{I}$. The mid-price $S_t$ follows a controlled diffusion process:
\begin{equation}
dS_t = w_t dt + \sigma(I_t) dW_t,
\end{equation}
where $\sigma(i)$ is the regime-dependent volatility, and $w_t$ is the drift controlled by the inner adversary.

The MM holds inventory $q_t \in \mathcal{Q} = \{-Q_{\max}, \dots, Q_{\max}\}$ and cash $m_t \in \mathbb{R}$. The inventory dynamics are pure jump processes driven by the execution of limit orders:
\begin{equation}
dq_t = dN^b_t - dN^a_t,
\end{equation}
where $N^b_t$ and $N^a_t$ are Poisson processes with intensities $\Lambda^b(u^b) = A e^{-k u^b}$ and $\Lambda^a(u^a) = A e^{-k u^a}$, controlled by the MM's spreads $u^b, u^a$ and the market depth parameters $A, k$.
Mapping to our general framework (Def.~\ref{def:hybrid}), we have the physical state: $X_t = (S_t, q_t, m_t)$. Note that $S_t$ and $m_t$ are continuous, while $q$ is discrete. The MM is the \textit{micro-player} who chooses spread $u_t = ( u^a_t, u^b_t)$; The predator is the \textit{micro-adversary} chooses $w_t$ (price drift). The jump rate is state-independent, with magnitude $\rho (z)=1$. 

At the outer layer, the regime transition rates $\mu_{ij}(f,g)$ are controlled by a \textit{Macro-Attacker} ($f_t$) who seeks to maximize the MM's disutility (or induce a ``Crisis'' regime where $\sigma$ is high); and a \textit{Stabilizer}, ($g_t$) who Seeks to maintain the ``Calm'' regime.
The outer value function $U_i(t,q)$ is computed by substituting the inner value $v_{i,q}$ into the outer objective. 


We formulate the inner layer as a zero-sum differential game. The MM maximizes the Constant Absolute Risk Aversion (CARA) utility of terminal wealth, $U(x) = -\exp(-\gamma (m_T + q_T S_T))$, where $\gamma$ is the risk aversion parameter.
The SP observes the MM's inventory $q_t$ and exerts price pressure $w_t$ to minimize the MM's Certainty Equivalent, subject to a quadratic cost $\frac{1}{2\xi} w_t^2$ representing the capital cost or risk of manipulation.


\subsection{Hierarchical Solution: Matrix Exponential and Approximate Equilibrium}

Using the Ansatz $V_i(t, S, q, m) = -\exp(-\gamma(m + qS + \theta_i(t,q)))$, the inner Hamiltonian $\mathcal{H}_i$ decomposes additively due to the separation of drift (price) and jump (execution) controls. 
The SP minimizes the Hamiltonian component associated with the price drift:
$\min_{w} \left[ w \partial_S V - V \frac{1}{2\xi} w^2 \right].$
Using $\partial_S V = -\gamma q V$ and factoring out $-V > 0$, the optimization yields a closed-form structural reaction function:
\begin{equation}
\label{eq:predator-strat}
w^*(t, q) = -\xi \gamma q.
\end{equation}
This strategy reveals a \emph{mean-averting} behavior: if the MM is long ($q>0$), the SP pushes the price down ($w^* < 0$) to devalue the position; if short, the SP pushes the price up.



Simultaneously, the MM maximizes the trading component:
\begin{equation}
\max_{u} \sum_{side \in \{a,b\}} \Lambda^{side}(u^{side}) \left( 1 - e^{-\gamma(u^{side} + \Delta \theta_{side})} \right),
\end{equation}
where $\Delta \theta_{a} = \theta(q-1)-\theta(q)$ and $\Delta \theta_{b} = \theta(q+1)-\theta(q)$. This recovers the standard Avellaneda-Stoikov spread formula adjusted for inventory shadow cost.
Substituting the optimal strategies back into the HJB equation, the predatory term contributes a quadratic penalty scaled by inventory size:
\begin{equation}
w^* (-\gamma q) - \frac{1}{2\xi}(w^*)^2 = \frac{1}{2}\xi \gamma^2 q^2.
\end{equation}
Consequently, the inventory value function $\theta_i(t,q)$ satisfies the coupled system of ODEs:
\begin{align}
\label{eq:modified-AS-HJB}
-\dot{\theta}_i(t,q) &= \underbrace{\frac{1}{2}\gamma \sigma_i^2 q^2}_{\text{Volatility Risk}} + \underbrace{\frac{1}{2}\xi \gamma^2 q^2}_{\text{Predatory Risk}}  + \sum_{side \in \{a,b\}} \frac{A}{\gamma} \left( 1 + \frac{\gamma}{k} \right)^{-\frac{k}{\gamma}} e^{-\gamma \Delta \theta_{side}} \nonumber \\
&+ \sum_{j \neq i} \mu_{ij}(f,g) \frac{1}{\gamma} \left( 1 - e^{-\gamma(\theta_j - \theta_i)} \right).
\end{align}

\begin{remark}[Risk Isomorphism]
The Hamiltonian separability preserves the tractability of the solution while providing a key insight. The presence of a strategic predator ($\xi > 0$) is mathematically isomorphic to an increase in market volatility. The MM perceives an \emph{effective volatility} $\sigma_{eff}^2(i) = \sigma_i^2 + \xi \gamma$. This implies that in the presence of predatory order flow, the optimal policy is to widen spreads and liquidate inventory faster, exactly as one would in a high-volatility environment.
\end{remark}



Under CARA utility, we define the value function and its exponential transformation as:
\begin{equation*}
V_i(t,S,q,m) = -\exp\!\big(-\gamma[m+qS+\theta_i(t,q)]\big), \qquad
v_{i,q}(t) := e^{-\gamma\theta_i(t,q)}.
\end{equation*}
Substituting optimal quotes into the HJB equation reduces the system to a linear ODE:
\begin{equation*}
\dot{v}(t) = M(t)v(t), \qquad
v(T) = \mathbf{1}.
\end{equation*}
The generator $M$ acts on the state space stacked by regimes $i=1,\dots,N$ and inventory $q \in \{-Q_{\max},\dots,Q_{\max}\}$. It decomposes into micro-structure and macro-switching blocks:
\begin{equation*}
M = D + \big(Q \otimes I_{|\mathcal{Q}|}\big).
\end{equation*}
Here, $Q$ is the regime transition matrix ($Q_{ij}=\mu_{ij}$ for $i\neq j$, row-sums zero). The block-diagonal matrix $D = \mathrm{diag}(A_1,\dots,A_N)$ captures the micro-dynamics. Each block $A_i$ is tridiagonal in the inventory dimension $q$, containing:
1. Diagonal risk \& outflow: $\frac{1}{2}\gamma^2(\sigma_i^2+\xi\gamma)q^2 - (\Lambda^{a}_i + \Lambda^{b}_i)$;
  2. off-diagonal: $\Lambda^{\text{side}}_i e^{-\gamma u^{*,\text{side}}_i}$ at $(q, q\pm 1)$.

For outer parameters piecewise-constant on $[t,T]$, the solution is explicit:
\begin{equation}
v(t) = \exp (- M\tau )\mathbf{1}, \qquad \tau := T-t.
\end{equation}

\paragraph{Regime mixing and expected variance.}
For small horizons $\tau$, we expand the matrix exponential to characterize how regime uncertainty affects pricing. Using the Feynman-Kac representation, the inventory cost $\theta_i(t,q)$ is driven by the expected accumulated variance. Expanding the solution to second order in $\tau$ yields (when $q$ is at the boundaries, remove the coefficient $2$ in the \emph{monopoly rent} term):
\begin{equation}
\label{eq:theta-first}
\theta_i(t,q)
= \frac{q^2}{2}\Big(\gamma\,w_i(\tau)+\gamma^2\xi\,\tau\Big)
- \frac{2A}{\gamma}\Big(1+\frac{\gamma}{k}\Big)^{-k/\gamma}\tau
+ \mathcal{O}(\tau^3).
\end{equation}
Here, $w_i(\tau)$ represents the \emph{expected integrated variance} starting from regime $i$. By expanding the generator $e^{Qu} \approx I + Qu$, we explicitly capture the regime mixing effect. Letting $s_i := \sigma_i^2$:
\begin{align}
\label{eq:wtau-expansion}
w(\tau) &:= \int_0^\tau [e^{Qu} s]_i \, du \approx \int_0^\tau [(I + Qu) s]_i \, du \nonumber \\
&= \sigma_i^2\tau + \frac{1}{2}\sum_{j \neq i} \mu_{ij}(\sigma_j^2 - \sigma_i^2)\,\tau^2 + \mathcal{O}(\tau^3).
\end{align}
The $\mathcal{O}(\tau^2)$ term captures the \emph{Regime Risk}: the probability-weighted drift into different volatility states. Thus, for very short horizons, the MM prices using the current regime's volatility. As $\tau$ increases, the pricing formula ``bends'' to incorporate the volatilities of connected regimes.

\paragraph{Optimal quotes and time-varying spreads.}
Defining the effective risk factor $C_i(\tau) := \gamma w_i(\tau) + \gamma^2\xi \tau$, the inventory indifference pricing implies:
\begin{equation*}
\Delta\theta_a \approx \Big(\tfrac{1}{2}-q\Big)C_i(\tau), \qquad
\Delta\theta_b \approx \Big(q+\tfrac{1}{2}\Big)C_i(\tau).
\end{equation*}
The resulting optimal spreads $u^*$ and reservation price $r$ are:
\begin{equation*}
u^*_{i}(t,q) = \frac{1}{\gamma}\ln\!\Big(1+\frac{\gamma}{k}\Big) + \frac{1}{2}C_i(\tau), \qquad
r_i(t,q) = S_t - q C_i(\tau).
\end{equation*}
This demonstrates that spreads widen pre-emptively based on future expected volatility $w_i(\tau)$, pricing in the macro-attacker's threat before the regime shift occurs.


\subsection{Macro Equilibrium (Outer HJI)}

Let $f_t$ (Attacker) and $g_t$ (Stabilizer) control the regime generator $\mu_{ij}(f,g)$ and micro-parameters.
We posit that the macro-agents optimize against the \emph{anticipated} inventory cost priced in by the Market Maker. Thus, the outer-layer running cost $\varphi_i(q;f,g)$ is defined directly by the inner value function $\theta_i$ over the horizon $\tau$:
\begin{equation*}
\varphi_i(q;f,g) := \theta_i(t,q) \approx \frac{q^2}{2}\Big(\gamma w_i(\tau; f,g)+\gamma^2\xi\tau\Big) - \text{Profit}(\tau).
\end{equation*}
This modeling choice implies a \emph{sentiment-driven interaction}: the macro-attacker seeks to maximize the Market Maker's forward-looking risk assessment (which drives liquidity drying), rather than merely the instantaneous volatility.

The macro value function $U_i(t,q)$, representing the cumulative market stress, satisfies the Isaacs equation:
\begin{equation}
\label{eq:macroHJI}
-\partial_t U_i(t,q) = \min_{g\in\Delta(\mathcal{A}_D)} \max_{f\in\Delta(\mathcal{A}_A)}
\left\{
\varphi_i(q;f,g) + \sum_{j\neq i}\mu_{ij}(f,g) \big(U_j(t,q) - U_i(t,q)\big)
\right\}.
\end{equation}
\begin{remark}[Behavioral Interpretation]
By utilizing the integrated variance $w_i(\tau)$ within the running cost, this formulation creates a feedback loop where the macro-agents are highly sensitive to \emph{future} regime risks. The switching probability enters twice: once in the MM's pricing ($w_i$) and again in the outer value dynamics ($\sum \mu_{ij} \Delta U$). This creates a ``Hyper-Alert'' equilibrium where attackers preemptively strike as soon as the \emph{expectation} of future volatility rises, mirroring the self-fulfilling nature of liquidity crises.
\end{remark}

Let $\Delta_{ij}(t,q) := U_j(t,q) - U_i(t,q)$ be the stability gap (the cost impact of switching from $i$ to $j$).

\begin{enumerate}
    
\item \emph{Affine Control:} If the transition rates $\mu_{ij}$ are controllable within $[\underline{\mu}_{ij}, \overline{\mu}_{ij}]$, $\mu_{i j}(f, g)=\mu_{i j}^{0}+f \cdot \lambda_{i j}^{\mathrm{att}}-g \cdot \lambda_{i j}^{\mathrm{stab}}$ the optimization decouples into pointwise Bang-Bang switches.
The Attacker ($f$) maximizes the drift toward higher cost regimes, while the Stabilizer ($g$) minimizes it:
\begin{align*}
f^*(t) = \mathbb{I}_{\left\{ \sum_{j \neq i} \lambda_{ij}^{\text{att}} \Delta_{ij} < 0 \right\}},  \qquad
g^*(t)  = \mathbb{I}_{\left\{ \sum_{j \neq i} \lambda_{ij}^{\text{stab}} \Delta_{ij} < 0 \right\}}.
\end{align*}
This highlights the conflict: when a regime switch is dangerous ($\Delta_{ij} > 0$), the Attacker pushes the accelerator ($\overline{\mu}$) while the Stabilizer slams the brake ($\underline{\mu}$).

\item \emph{Quadratic Costs:} We relax the bounded control assumption and instead impose quadratic effort penalties $\frac{\rho_f}{2}f^2$ and $\frac{\rho_g}{2}g^2$ in the outer Hamiltonian. Assuming the transition rates remain affine in effort ($\mu_{ij} = \mu_{ij}^0 + f\lambda_{ij}^{\text{att}} - g\lambda_{ij}^{\text{stab}}$), the control-dependent part of the Hamiltonian is:
\begin{equation*}
\mathcal{H}(f,g) \propto f \left( \sum_{j \neq i} \lambda_{ij}^{\text{att}} \Delta_{ij} \right) - g \left( \sum_{j \neq i} \lambda_{ij}^{\text{stab}} \Delta_{ij} \right) - \frac{\rho_f}{2}f^2 - \frac{\rho_g}{2}g^2.
\end{equation*}
The first-order optimality conditions ($\partial_f \mathcal{H} = 0, \partial_g \mathcal{H} = 0$) yield explicit proportional feedback rules:
\begin{align*}
f^*(t) &= \frac{1}{\rho_f} \left[ \sum_{j \neq i} \lambda_{ij}^{\text{att}} \big( U_j(t,q) - U_i(t,q) \big) \right]^+, \\
g^*(t) &= \frac{1}{\rho_g} \left[ \sum_{j \neq i} \lambda_{ij}^{\text{stab}} \big( U_i(t,q) - U_j(t,q) \big) \right]^+,
\end{align*}
where $[x]^+ = \max(0, x)$.
This result characterizes the macro-agents as \emph{variable-gain controllers}: the intensity of their intervention scales linearly with the severity of the stability gap. For instance, the Attacker exerts minimal effort when the system is robust ($\Delta_{ij} \approx 0$) but surges activity proportionally as the MM's inventory vulnerability increases ($\Delta_{ij} \gg 0$).
\end{enumerate}

\subsection{Numerical Illustration}

We demonstrate the equilibrium strategies and risk isomorphism principle using calibrated Bitcoin (BTC) market data. The experiment compares two market making strategies facing a strategic predatory trader:
\begin{enumerate}
    \item \textbf{Vanilla AS}: Standard Avellaneda-Stoikov strategy, unaware of predatory drift
    \item \textbf{Equilibrium AS}: Modified strategy using effective volatility $\sigma_{\text{eff}}^2 = \sigma^2 + \xi \gamma$ to account for predatory risk
\end{enumerate}

\subsubsection{Calibration from BTC Data}

We calibrate regime-switching parameters from Kraken BTC-USD 30-minute OHLCV data (December 7--14, 2025). Using rolling volatility with $K$-means clustering, we identify two distinct regimes:

\begin{itemize}
    \item \textbf{Stable regime} (Regime 0): $\sigma_0 = 0.2253$ (22.53\% annualized)
    \item \textbf{Volatile regime} (Regime 1): $\sigma_1 = 0.5305$ (53.05\% annualized)
    \item Volatility ratio: $\sigma_1 / \sigma_0 = 2.35$
\end{itemize}

Empirical transition matrix estimation yields a base transition rate of $\mu_0 = 30$ per day, corresponding to an average holding time of 48 minutes per regime. Figure~\ref{fig:btc-regime-calibration} shows the calibrated regime evolution with price dynamics colored by regime state (green for stable, red for volatile).

\subsubsection{Counterfactual Simulation Design}

We simulate 12 hours of market making activity (December 12, 2025, 15:00--03:00) with the following setup:

\begin{itemize}
    \item \textbf{Initial state}: $S_0 = \$90{,}863.90$, starting in stable regime ($I_0 = 0$)
    \item \textbf{Timestep}: $\Delta t = 15$ seconds (2,880 total steps)
    \item \textbf{Regime drift}: $\mu_0 = \mu_1 = 0$ (only predator affects drift)
    \item \textbf{Predator strategy}: Optimal drift control $w^*(q) = -\xi \gamma q$ with cost coefficient $\xi = 10.0$
    \item \textbf{MM risk aversion}: $\gamma = 0.02$
    \item \textbf{Order arrival}: Poisson intensity $\Lambda(\delta) = \lambda_0 e^{-\kappa \delta}$ with $\lambda_0 = 250{,}000$ per year, $\kappa = 10.0$
    \item \textbf{Inventory constraint}: $q \in [-10, 10]$ BTC
    \item \textbf{Monte Carlo paths}: 1,000 trajectories
\end{itemize}

Both strategies face the \emph{same} strategic predator who observes their inventory in real-time and applies adversarial drift. The key difference is that Vanilla AS uses the actual volatility $\sigma_i$ in the spread formula, while Equilibrium AS uses the effective volatility $\sigma_{\text{eff},i} = \sqrt{\sigma_i^2 + \xi \gamma}$ derived from Remark~1 (Risk Isomorphism).

\subsubsection{Results and Behavioral Analysis}

Figure~\ref{fig:mm-simulation} presents the counterfactual simulation results. The top panel shows price evolution with equilibrium AS spread bands, colored by regime state (green for stable, red for volatile). The simulation exhibits realistic regime dynamics with 9 regime switches over 12 hours, spending approximately equal time in each regime (54.5\% volatile, 45.5\% stable).

Table~\ref{tab:strategy-comparison} summarizes the performance comparison across 1,000 Monte Carlo paths:

% \begin{itemize}
%     \item \emph{Macro stabilizer} $M$: chooses $u_t$ to make crisis
%     regimes less frequent or less persistent, at the cost of deploying
%     liquidity, adjusting collateral rules, or imposing frictions.
%     \item \emph{Macro stressor} $D$: chooses $v_t$ to amplify the
%     likelihood and persistence of stressed regimes, representing
%     adverse macro conditions or a worst-case environment.
%     \item \emph{Micro hedger} $H$: chooses a self-financing trading
%     strategy $\theta_t \in \mathbb{R}^{m+1}$ specifying holdings in
%     $X_t$ to hedge a BTC-linked liability $L_T(X_T,I_T)$.
%     \item \emph{Micro disturbance} $A$: chooses $z_t$ to perturb the
%     local diffusion and jump characteristics in \eqref{eq:btc-inner-dynamics}
%     within an uncertainty set, modeling microstructure noise or
%     adversarial short-horizon behavior.
% \end{itemize}

% The hedger's wealth process satisfies
% \begin{equation}
% \label{eq:wealth-dynamics}
%     dW_t
%     =
%     \theta_t^\top dX_t
%     + r\bigl(W_t - \theta_t^\top X_t\bigr)\,dt,
% \end{equation}
% where $r$ is the risk-free rate and $\theta_t$ is progressively
% measurable with respect to the filtration generated by $(X_t,I_t)$.

% \subsubsection{Inner micro-level game}

% For fixed macro strategies $(u,v)$, the pair $(X_t,I_t)$ evolves as in
% \eqref{eq:btc-inner-dynamics}\eqref{eq:btc-macro-generator}, and the
% hedger $H$ interacts with the disturbance $A$ at the micro time scale.
% The inner objective is to hedge the terminal liability $L_T$ while
% penalizing both hedging effort and micro-level perturbations. For given
% initial state $(t,x,i,w)$ and macro controls $(u,v)$, define the
% inner performance functional
% \begin{equation}
% \label{eq:inner-cost}
% \begin{aligned}
%     J_{\mathrm{mic}}^{u,v}(t,x,i,w;\theta,z)
%     =&\ 
%     \mathbb{E}^{t,x,i,w}_{u,v}
%     \Bigl[
%         \ell_{\mathrm{mic}}
%         \bigl(X_s,I_s,W_s,\theta_s,z_s\bigr)
%         \\
%         &\quad + \lambda_L
%         \bigl(
%             W_T - L_T(X_T,I_T)
%         \bigr)^2
%     \Bigr],
% \end{aligned}
% \end{equation}
% where $\ell_{\mathrm{mic}}$ is a running cost and $\lambda_L > 0$
% weights the terminal hedging error. The inner value function in regime
% $i$ is
% \begin{equation}
% \label{eq:inner-value}
%     V_i(t,x,w;u,v)
%     =
%     \inf_{\theta}
%     \sup_{z}
%     J_{\mathrm{mic}}^{u,v}(t,x,i,w;\theta,z).
% \end{equation}
% Under suitable Isaacs and regularity conditions, the collection
% $\{V_i\}_{i\in\mathcal{I}}$ satisfies a coupled HamiltonJacobiIsaacs
% system in the continuous state $(x,w)$ with switching terms driven by
% $Q(u_t,v_t)$.

% \subsubsection{Outer macro-level game}

% At the slower time scale, the macro stabilizer $M$ and macro stressor
% $D$ choose $(u_t,v_t)$ to shape the regime-switching kernel
% \eqref{eq:btc-macro-generator}, anticipating the optimal inner-layer
% responses encoded in the value functions $V_i$. The macro cost trades
% off inner hedging performance, regime occupancy, and the effort of
% kernel manipulation. For initial condition $(t,x,i)$, define the
% macro-level performance functional
% \begin{equation}
% \label{eq:outer-cost}
% \begin{aligned}
%     J_{\mathrm{mac}}(t,x,i;u,v)
%     =
%     \mathbb{E}^{t,x,i}_{u,v}
%     \Bigl[
%         \int_t^{T}
%         \ell_{\mathrm{mac}}
%         \bigl(s,X_s,I_s,u_s,v_s, V_{I_s}(s,X_s,W_s;u,v)\bigr)\,ds
%         \\
%         \qquad + 
%         g\bigl(X_T,I_T, V_{I_T}(T,X_T,W_T;u,v)\bigr)
%     \Bigr],
% \end{aligned}
% \end{equation}
% where $\ell_{\mathrm{mac}}$ penalizes time spent in stressed regimes,
% macro control effort, and poor inner-layer performance, and $g$
% captures terminal regime and hedging metrics.

% The outer macro value function is then
% \begin{equation}
% \label{eq:outer-value}
%     W_i(t,x)
%     =
%     \inf_{u}
%     \sup_{v}
%     J_{\mathrm{mac}}(t,x,i;u,v),
% \end{equation}
% subject to the constraint that $V_i(\cdot,\cdot,\cdot;u,v)$ solves the
% inner game \eqref{eq:inner-value}. This yields a double-layer game: a
% fast inner micro game between hedger and disturbance, and a slow outer
% macro game over the regime-switching kernel. The associated outer
% value functions $\{W_i\}_{i\in\mathcal{I}}$ satisfy a second HamiltonJacobiIsaacs
% system in $(t,x)$, with running costs and switching terms that depend
% on the inner-layer values $V_i$ through \eqref{eq:outer-cost}.



\section{Conclusion}

We developed a two-layer hybrid control architecture in which a fast-time controller interacts with a strategically regulated 
regime-switching mechanism.  
This perspective casts the overall system as a piecewise-deterministic 
Markov process, allowing a unified treatment of continuous dynamics 
and discrete transitions through a single Dynkin identity.  
The resulting hierarchy produces coupled HamiltonJacobi equations, 
well-posedness guarantees for the corresponding value functions, 
and a monotonicity property showing how adjustments to the transition 
kernel influence the family of mode-coupled Riccati flows.
The framework is broadly applicable to systems where an inner 
continuous-time controller must operate under a slowly evolving 
environment, stress regime, or macro-level process.  
The financial case study illustrates how the architecture can encode 
robust hedging and uncertainty-aware regime regulation, but the 
methodology extends naturally to engineering, economic, and 
multi-agent decision systems with layered time scales.

Several directions remain open.  
(i) Data-driven estimation of transition intensities and uncertainty 
sets would connect the outer-layer regulator to empirical regime 
dynamics.  
(ii) Robustness margins for parametric uncertainty in the coupled 
Riccati flows would strengthen the guarantees obtained at both layers.  
(iii) Partial-observation extensions, in which only asset prices or 
aggregate signals are observed, require belief-state or filter-driven 
value functions and would broaden the scope of the hierarchical model.  
These directions would further enhance the proposed architecture into a 
more comprehensive tool for layered control and decision-making in 
hybrid stochastic systems.



%% The Appendices part is started with the command \appendix;
% %% appendix sections are then done as normal sections
% \appendix
% \section{Additional Proofs}
% \label{app1}

% \begin{proof}
%     Hello world
% \end{proof}

%% For citations use: 
%%       \cite{<label>} ==> [1]

%%

%% If you have bib database file and want bibtex to generate the
%% bibitems, please use
%%
\bibliographystyle{elsarticle-num} 
\bibliography{ref}

%% else use the following coding to input the bibitems directly in the
%% TeX file.

%% Refer following link for more details about bibliography and citations.
%% https://en.wikibooks.org/wiki/LaTeX/Bibliography_Management


% \begin{thebibliography}{00}

% %% For numbered reference style
% %% \bibitem{label}
% %% Text of bibliographic item


% \end{thebibliography}
\end{document}

\endinput
%%
%% End of file `elsarticle-template-num.tex'.
